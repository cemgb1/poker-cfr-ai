# poker-cfr-ai
# üÉè Poker CFR AI - Complete Strategy Training System

A professional-grade Counterfactual Regret Minimization (CFR) implementation for poker artificial intelligence. This system trains optimal strategies for all 169 starting hands across both preflop and postflop scenarios, using advanced machine learning techniques employed by commercial poker solvers.

## üéØ What This System Does

**Trains a Complete Poker AI** that can provide optimal strategy recommendations for any poker situation:
- **Preflop**: Opening, calling, raising, and folding decisions for all 169 possible starting hands
- **Postflop**: Betting, calling, and folding strategies across different board textures and hand strengths
- **Position-Aware**: Different strategies for Button (BTN) vs Big Blind (BB) positions
- **Stack-Depth Conscious**: Adjusts recommendations based on effective stack sizes

**Example Outputs:**
- "With AK‚ô† on the Button facing a raise: **RAISE** (87% frequency)"
- "With 77 on A‚ô†8‚ô•2‚ô¶ board in Big Blind: **CALL** (65% frequency)"
- "With A‚ô†3‚ô† on 9‚ô†7‚ô†2‚ô• board: **RAISE** (flush draw + overcards)"

## üß† The Science Behind CFR

### What is Counterfactual Regret Minimization?

CFR is a game theory algorithm that learns optimal strategies by:

1. **Playing against itself** millions of times
2. **Tracking regret** for not taking better actions
3. **Minimizing regret** over time to approach Nash equilibrium
4. **Converging to optimal play** that no opponent can exploit

This is the same fundamental approach used by:
- **Libratus** (beat top human pros in 2017)
- **Pluribus** (beat 5 human pros simultaneously in 2019)
- **Commercial solvers** like PioSOLVER and GTO+

### Why CFR Works for Poker

Poker is a game of **imperfect information** - you can't see your opponent's cards. CFR excels at these scenarios because it:
- **Handles uncertainty** by considering all possible opponent holdings
- **Balances strategies** to remain unexploitable
- **Finds equilibrium** solutions that are mathematically optimal
- **Scales efficiently** to complex game trees

## üèóÔ∏è System Architecture

### The Big Picture
```
Training (Cloud) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ Export ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ Local Deployment
   Heavy Compute           CSV Files      Fast Lookups
   $1-2 total cost        ~50MB total     Instant queries
   One-time training      Portable        Offline capable
```

### Strategic Hand Grouping

Instead of training 169 individual hands separately, the system uses **strategic grouping**:

- **Premium Pairs**: AA, KK, QQ (play aggressively)
- **Medium Pairs**: JJ, TT, 99 (position-dependent)  
- **Small Pairs**: 22-88 (set-mining focused)
- **Premium Aces Suited**: AKs, AQs, AJs (high aggression)
- **Suited Connectors**: T9s, 98s, 87s (drawing potential)
- **Offsuit Trash**: 72o, 83o, etc. (mostly fold)

This approach makes the problem **computationally tractable** while maintaining strategic accuracy.

### Equal Distribution Training

Traditional CFR can miss important scenarios. This system uses **forced scenario training**:

```python
# Instead of random training:
while iterations < max_iterations:
    train_random_scenario()  # Some scenarios might never be seen!

# We use targeted training:
while undertrained_scenarios_exist():
    train_least_seen_scenario()  # Guarantees comprehensive coverage
```

This ensures every possible poker situation gets adequate training time.

## üìä Scale and Complexity

### Preflop Scenarios: ~1,500 total
- 18 hand groups √ó 2 positions √ó 7 action histories √ó 3 stack depths
- Examples: "Premium pairs in Button position facing a 3-bet with deep stacks"

### Postflop Scenarios: ~485,000 total  
- 18 hand groups √ó 16 board textures √ó 17 hand interactions √ó 2 positions √ó 4 preflop histories √ó 7 postflop histories √ó 3 stack depths
- Examples: "Medium pairs on paired board with set, in Big Blind, after calling preflop raise, facing continuation bet"

### Why So Many Scenarios?

Poker strategy depends on **context**:
- **AK on A‚ô†7‚ô•2‚ô¶**: Strong (top pair, good kicker) 
- **AK on A‚ô†A‚ô•7‚ô¶**: Weaker (trips likely, kicker plays down)
- **77 on 7‚ô†8‚ô†9‚ô¶**: Very strong (set with straight/flush draws possible)
- **77 on A‚ô†K‚ô†Q‚ô¶**: Weak (low set on dangerous board)

Each context requires different optimal play, hence the massive scenario space.

## üî¨ Technical Innovation

### 1. Scenario-Based Stopping Criterion
```
Traditional: "Train for 1 million iterations"
This System: "Train until every scenario has 300+ visits"
```
**Result**: Guaranteed comprehensive coverage instead of random sampling.

### 2. Cloud-Optimized Architecture
- **Training**: Heavy computation on powerful cloud instances
- **Inference**: Lightweight CSV lookups on local machines
- **Cost-Effective**: Train once for $1-2, query forever for free

### 3. Professional Hand Evaluation
```python
# Considers multiple factors:
- Hand strength (pair, two pair, straight, etc.)
- Board texture (dry, wet, coordinated, paired)  
- Position (early, late, blinds)
- Action history (raise, call, check sequences)
- Stack depth (short, medium, deep)
- Drawing potential (flush draws, straight draws)
```

## üéÆ Real-World Applications

### For Poker Players
- **Study tool**: Learn GTO (Game Theory Optimal) strategies
- **Training partner**: Practice against unexploitable AI
- **Hand analysis**: Review specific situations and optimal plays
- **Strategy development**: Understand modern poker theory

### For Developers
- **Game AI research**: Foundation for other imperfect information games
- **Algorithm study**: Learn CFR implementation techniques
- **Machine learning**: Example of self-play reinforcement learning
- **System design**: Cloud training + local deployment patterns

### For Researchers
- **Game theory**: Study Nash equilibrium convergence
- **Computer science**: Scalable CFR implementations
- **Mathematics**: Regret minimization in practice
- **AI development**: Multi-agent learning systems

## üèÜ Commercial-Grade Features

### What Makes This Professional

1. **Complete Coverage**: All 169 hands, all major situations
2. **Scalable Training**: Handles 485k+ scenarios efficiently  
3. **Quality Assurance**: Equal distribution guarantees no blind spots
4. **Production Ready**: CSV export for fast deployment
5. **Cost Optimized**: Cloud training designed for minimal expense
6. **Maintainable**: Clean code structure with proper abstractions

### Comparison to Commercial Solvers

| Feature | This System | PioSOLVER | GTO+ |
|---------|-------------|-----------|------|
| **Preflop Coverage** | ‚úÖ All 169 hands | ‚úÖ All hands | ‚úÖ All hands |
| **Postflop Training** | ‚úÖ Major textures | ‚úÖ All textures | ‚úÖ All textures |
| **Hand Grouping** | ‚úÖ Strategic groups | ‚úÖ Advanced | ‚úÖ Advanced |
| **Cloud Training** | ‚úÖ GCP optimized | ‚ùå Local only | ‚ùå Local only |
| **Cost** | ~$2 training | $475+ license | $250+ license |
| **Open Source** | ‚úÖ Full access | ‚ùå Proprietary | ‚ùå Proprietary |

## üåü Why This Implementation Matters

### For the Poker Community
- **Democratizes GTO study**: High-quality solver without expensive licenses
- **Educational value**: Open source allows understanding the algorithms
- **Research platform**: Foundation for poker AI research
- **Customization**: Modify for specific game variants or conditions

### For the AI Community  
- **CFR Implementation**: Complete, working example of modern CFR
- **Self-Play Learning**: Demonstrates convergence to optimal strategies
- **Scalability Solutions**: Handles large state spaces efficiently
- **Cloud ML Pipeline**: End-to-end training and deployment workflow

### For Computer Science
- **Algorithm Engineering**: Optimized CFR with practical considerations
- **System Design**: Separation of training and inference concerns
- **Performance Optimization**: Cloud-optimized for cost-effectiveness
- **Data Pipeline**: Training ‚Üí Export ‚Üí Query architecture

## üîÆ Future Possibilities

### Immediate Extensions
- **Multi-street training** (flop, turn, river)
- **Tournament scenarios** (ICM considerations)  
- **Multi-way pots** (3+ players)
- **Different bet sizes** (25%, 50%, 75%, pot, overbet)

### Advanced Features
- **Web interface** for strategy queries
- **Mobile app** for on-the-go study
- **Real-time advice** during online play (where legal)
- **Custom training** for specific opponent types

### Research Directions
- **Neural network integration** (CFR-D, Neural Fictitious Self-Play)
- **Abstraction improvements** (better hand bucketing)
- **Faster convergence** (Monte Carlo CFR variants)
- **Other poker variants** (PLO, tournaments, mixed games)

## üìö Educational Value

This system serves as a **complete textbook example** of:

- **Game theory** in practice
- **Machine learning** without neural networks
- **Self-play algorithms** and convergence
- **Large-scale optimization** problems
- **Cloud computing** for ML workloads
- **Software engineering** for AI systems

Whether you're a poker player wanting to improve, a developer learning AI techniques, or a researcher studying game theory, this implementation provides a solid foundation with professional-grade results.

---

*Built with game theory, optimized for the cloud, designed for real-world impact.*
